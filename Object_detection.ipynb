{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on Colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import fileinput\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "%cd /content/\n",
    "df = pd.read_csv('processed_data1.csv')\n",
    "df.head()\n",
    "\n",
    "train = df[(df['train_val_test']==1) | (df['train_val_test']==3)]\n",
    "train['classes'].value_counts()\n",
    "\n",
    "valid = df[df['train_val_test']==2]\n",
    "valid['classes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id '17rFdLEySkRdV9jOZaXsAH9uw0XcCcp4O'\n",
    "!unzip -q PyTorch-YOLOv3.zip\n",
    "\n",
    "%cd /content/PyTorch-YOLOv3/\n",
    "!pip3 install -q poetry\n",
    "!poetry -q install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/PyTorch-YOLOv3/data/\n",
    "!gdown --id '1FExoROsfs4o8KpFWqFQ3fx44Upz1fblG'\n",
    "!unzip -q images.zip\n",
    "\n",
    "!gdown --id '1PPgGczvZ2vghXWunFuyPXQHxKGXSVN4C'\n",
    "!unzip -q Enhace_ExDark.zip\n",
    "\n",
    "!gdown --id '1TVxBCiRhGRMQEKQay9nZumyUoNPdFpGy'\n",
    "!unzip -q labels.zip\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/PyTorch-YOLOv3/weights/\n",
    "!gdown --id '1ZaClZ5MjeLe_4C1lboxkx3Ecb9U8FDg3'\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/content/PyTorch-YOLOv3/data/custom/images/'\n",
    "os.chdir('/content/PyTorch-YOLOv3/data/custom/')\n",
    "\n",
    "train_file = 'train.txt'\n",
    "\n",
    "with open(train_file,'w') as tf:\n",
    "    for img in tqdm(train['path']):\n",
    "        file = img.split('/')[-1]\n",
    "        path = os.path.join(img_dir,file)\n",
    "        if os.path.isfile(path):\n",
    "            tf.write(path)\n",
    "            tf.write('\\n')\n",
    "    tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/content/PyTorch-YOLOv3/data/custom/images/'\n",
    "os.chdir('/content/PyTorch-YOLOv3/data/custom/')\n",
    "\n",
    "valid_file = 'valid.txt'\n",
    "\n",
    "with open(valid_file,'w') as vf:\n",
    "    for img in tqdm(valid['path']):\n",
    "        file = img.split('/')[-1]\n",
    "        path = os.path.join(img_dir,file)\n",
    "        if os.path.isfile(path):\n",
    "            vf.write(path)\n",
    "            vf.write('\\n')\n",
    "    vf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download pth file(weight of YOLOv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/PyTorch-YOLOv3/checkpoints/\n",
    "!gdown --id '1NnJkzdIRWJmCTYFBb5eCvUhf3UioYK-r'\n",
    "!gdown --id '1BhTMObdsC5SyTSY7PU8lhYABk4S58FiW'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run yolo-train --model config/yolov3-custom.cfg --data config/custom.data -e 30 --pretrained_weights weights/darknet53.conv.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save pth file to google cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# 指定要複製的檔案路徑\n",
    "source_file_path = '/content/PyTorch-YOLOv3/checkpoints/yolov3_ckpt_30.pth'  # 替換成你要上傳的檔案路徑\n",
    "\n",
    "# 指定目的地路徑\n",
    "destination_folder = '/content/drive/My Drive/result/'  # 替換成你要儲存的目的地資料夾路徑\n",
    "\n",
    "# 複製單一檔案到 Google Drive 中的指定目的地\n",
    "shutil.copy(source_file_path, destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run yolo-test --model config/yolov3-custom.cfg --data config/custom.data --weights checkpoints/yolov3_ckpt_30.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/PyTorch-YOLOv3/\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "import cv2\n",
    "from pytorchyolo import detect, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/PyTorch-YOLOv3/\n",
    "custom_config = './config/yolov3-custom.cfg'\n",
    "model_2_weights = './checkpoints/yolov3_ckpt_30.pth'\n",
    "model_1_weights = './checkpoints/yolov3_ckpt_23.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "import cv2\n",
    "from pytorchyolo import detect, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def predict_objects(config,weights,image):\n",
    "    \n",
    "    '''this function takes inputs as model's config,weights file and input image and gives output image \n",
    "    with objects predicted and bounding box drawn on input image'''\n",
    "    \n",
    "    # define the labels\n",
    "    labels = {0:'bicycle',1:'boat',2:'bottle',3:'bus',4:'car',5:'cat',6:'chair',7:'cup',8:'dog',9:'motorbike',10:'people',11:'table'}\n",
    "    \n",
    "    # Load the YOLO model\n",
    "    model = models.load_model(config, weights)\n",
    "    output_folder = '/content/PyTorch-YOLOv3/data/custom/output/'\n",
    "    # Load the image as a numpy array\n",
    "    img = cv2.imread(image)\n",
    "    file_name = os.path.basename(image)\n",
    "    # Convert OpenCV bgr to rgb\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Runs the YOLO model on the image \n",
    "    boxes = detect.detect_image(model, img)\n",
    "        \n",
    "    # load the image\n",
    "    data = pyplot.imread(image)\n",
    "    plt.imsave(output_folder+file_name, data)\n",
    "    # plot the image\n",
    "    pyplot.imshow(data)\n",
    "    \n",
    "    # get the context for drawing boxes\n",
    "    ax = pyplot.gca()\n",
    "    \n",
    "    # plot each box\n",
    "    for box in boxes:\n",
    "        # get coordinates\n",
    "        x1, y1, x2, y2 = box[0], box[1], box[2], box[3]\n",
    "        \n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        \n",
    "        # create the shape\n",
    "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw text and score in top left corner\n",
    "        label = \"%s (%.3f)\" % (labels[box[5]], box[4])\n",
    "        print(label)\n",
    "        pyplot.text(x1, y1, label, color='white')\n",
    "        \n",
    "    # show the plot\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_images = ['/content/PyTorch-YOLOv3/data/custom/images/2015_00308.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_00293.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_02239.JPEG'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_05213.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_05235.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_02770.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_04820.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_00281.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_04034.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_05270.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_03332.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_02137.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_00351.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_00966.jpg'\n",
    ",'/content/PyTorch-YOLOv3/data/custom/images/2015_02251.JPG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Remider: using model_2_weights require changing \"Enhace_Dark\" filename into \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/PyTorch-YOLOv3/\n",
    "for image in random_images:\n",
    "    predict_objects(custom_config,model_1_weights,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/PyTorch-YOLOv3/\n",
    "for image in random_images:\n",
    "    predict_objects(custom_config,model_2_weights,image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes(config,weights,image):\n",
    "    \n",
    "    # Load the YOLO model\n",
    "    model = models.load_model(config, weights)\n",
    "\n",
    "    # Load the image as a numpy array\n",
    "    img = cv2.imread(image)\n",
    "\n",
    "    # Convert OpenCV bgr to rgb\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Runs the YOLO model on the image \n",
    "    boxes = detect.detect_image(model, img)\n",
    "    \n",
    "    # Output will be a numpy array in the following format:\n",
    "    # [[x1, y1, x2, y2, confidence, class]]\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "# draw all results\n",
    "def draw_boxes(filename,boxes):\n",
    "    # load the image\n",
    "    data = pyplot.imread(filename)\n",
    "    # plot the image\n",
    "    pyplot.imshow(data)\n",
    "    # get the context for drawing boxes\n",
    "    ax = pyplot.gca()\n",
    "    # plot each box\n",
    "    for box in boxes:\n",
    "        # get coordinates\n",
    "        x1, y1, x2, y2 = box[0], box[1], box[2], box[3]\n",
    "        \n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        \n",
    "        # create the shape\n",
    "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw text and score in top left corner\n",
    "        label = \"%s (%.3f)\" % (labels[box[5]], box[4])\n",
    "        print(label)\n",
    "        pyplot.text(x1, y1, label, color='white')\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "labels = {0:'bicycle',1:'boat',2:'bottle',3:'bus',4:'car',5:'cat',6:'chair',7:'cup',8:'dog',9:'motorbike',10:'people',11:'table'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"/content/bbtest.jpg\"\n",
    "\n",
    "boxes = get_boxes(custom_config,model_1_weights,image)\n",
    "draw_boxes(image,boxes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
